{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f0c30e7-c5cc-41b2-8320-618b7f2c79f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import socket\n",
    "import platform\n",
    "import traceback\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "\n",
    "def test_ray_cluster(\n",
    "    *,\n",
    "    address: str = \"auto\",\n",
    "    namespace: str = \"ray_cluster_test\",\n",
    "    include_internal_kv: bool = True,\n",
    "    include_actors: bool = True,\n",
    "    include_tasks: bool = True,\n",
    "    include_placement_groups: bool = True,\n",
    "    run_per_node_exec_probe: bool = True,\n",
    "    run_object_store_probe: bool = True,\n",
    "    run_cpu_burn_probe: bool = False,\n",
    "    cpu_burn_seconds: float = 0.75,\n",
    "    per_node_timeout_s: float = 15.0,\n",
    "    verbose: bool = True,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Comprehensive Ray cluster diagnostic.\n",
    "\n",
    "    What it tries to answer:\n",
    "      - Are we connected to a Ray cluster? Which address?\n",
    "      - How many nodes does Ray detect? Which are alive?\n",
    "      - Node properties: NodeID, IP, resources, labels (if any), node manager info, etc.\n",
    "      - Cluster resources vs available resources (Ray scheduler view)\n",
    "      - Autoscaler status (if present on head / internal KV)\n",
    "      - Placement groups, actors, tasks summary (if enabled + available in your Ray version)\n",
    "      - Per-node execution probe: can we schedule a task on each node?\n",
    "      - Object store probe: can we put/get a few MB and report time?\n",
    "      - Optional CPU burn probe: light compute to verify distributed execution\n",
    "\n",
    "    Returns a JSON-serializable dict with results (best effort).\n",
    "    \"\"\"\n",
    "\n",
    "    result: Dict[str, Any] = {\n",
    "        \"meta\": {\n",
    "            \"timestamp_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "            \"host\": socket.gethostname(),\n",
    "            \"platform\": platform.platform(),\n",
    "            \"python\": platform.python_version(),\n",
    "            \"pid\": os.getpid(),\n",
    "            \"env\": {\n",
    "                \"RAY_ADDRESS\": os.environ.get(\"RAY_ADDRESS\"),\n",
    "                \"RAY_NAMESPACE\": os.environ.get(\"RAY_NAMESPACE\"),\n",
    "            },\n",
    "        },\n",
    "        \"connection\": {},\n",
    "        \"cluster\": {},\n",
    "        \"nodes\": {},\n",
    "        \"probes\": {},\n",
    "        \"warnings\": [],\n",
    "        \"errors\": [],\n",
    "    }\n",
    "\n",
    "    # --- Lazy imports: keep function usable even if some Ray submodules unavailable ---\n",
    "    try:\n",
    "        import ray\n",
    "        result[\"meta\"][\"ray_version\"] = getattr(ray, \"__version__\", \"unknown\")\n",
    "    except Exception as e:\n",
    "        result[\"errors\"].append(f\"Failed to import ray: {e}\")\n",
    "        return result\n",
    "\n",
    "    # Connect\n",
    "    try:\n",
    "        ctx = ray.init(address=address, namespace=namespace, ignore_reinit_error=True, log_to_driver=False)\n",
    "        # ctx can be ray.runtime_context.RuntimeContext-ish depending on version; keep minimal\n",
    "        result[\"connection\"] = {\n",
    "            \"address_requested\": address,\n",
    "            \"dashboard_url\": getattr(ctx, \"dashboard_url\", None),\n",
    "            \"redis_address\": getattr(ctx, \"address_info\", {}).get(\"redis_address\") if hasattr(ctx, \"address_info\") else None,\n",
    "            \"raylet_socket_name\": getattr(ctx, \"address_info\", {}).get(\"raylet_socket_name\") if hasattr(ctx, \"address_info\") else None,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        result[\"errors\"].append(f\"ray.init failed: {e}\")\n",
    "        result[\"errors\"].append(traceback.format_exc())\n",
    "        return result\n",
    "\n",
    "    # Helpers\n",
    "    def _safe(callable_, *args, **kwargs):\n",
    "        try:\n",
    "            return callable_(*args, **kwargs), None\n",
    "        except Exception as e:\n",
    "            return None, f\"{e}\\n{traceback.format_exc()}\"\n",
    "\n",
    "    # --- Cluster resource view ---\n",
    "    import ray\n",
    "\n",
    "    cr, err = _safe(ray.cluster_resources)\n",
    "    ar, err2 = _safe(ray.available_resources)\n",
    "    result[\"cluster\"][\"cluster_resources\"] = cr or {}\n",
    "    result[\"cluster\"][\"available_resources\"] = ar or {}\n",
    "    if err:\n",
    "        result[\"warnings\"].append(f\"ray.cluster_resources() failed: {err}\")\n",
    "    if err2:\n",
    "        result[\"warnings\"].append(f\"ray.available_resources() failed: {err2}\")\n",
    "\n",
    "    # --- Nodes: ray.nodes() returns dicts with rich info ---\n",
    "    nodes, err = _safe(ray.nodes)\n",
    "    node_list: List[Dict[str, Any]] = nodes or []\n",
    "    if err:\n",
    "        result[\"warnings\"].append(f\"ray.nodes() failed: {err}\")\n",
    "        node_list = []\n",
    "\n",
    "    alive = [n for n in node_list if n.get(\"Alive\", False)]\n",
    "    dead = [n for n in node_list if not n.get(\"Alive\", False)]\n",
    "\n",
    "    # Normalize node fields into a cleaner structure\n",
    "    def _node_summary(n: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        # Ray versions differ in exact keys; keep what exists.\n",
    "        out: Dict[str, Any] = {\n",
    "            \"node_id\": n.get(\"NodeID\") or n.get(\"NodeId\") or n.get(\"node_id\"),\n",
    "            \"alive\": bool(n.get(\"Alive\", False)),\n",
    "            \"node_name\": n.get(\"NodeName\") or n.get(\"NodeManagerAddress\") or n.get(\"Hostname\"),\n",
    "            \"ip\": n.get(\"NodeManagerAddress\") or n.get(\"IPAddress\") or n.get(\"ip\"),\n",
    "            \"resources_total\": n.get(\"Resources\", {}),\n",
    "            \"labels\": n.get(\"Labels\", None),  # newer Ray may expose Labels\n",
    "            \"raylet\": {\n",
    "                \"node_manager_hostname\": n.get(\"NodeManagerHostname\"),\n",
    "                \"node_manager_port\": n.get(\"NodeManagerPort\"),\n",
    "                \"object_manager_port\": n.get(\"ObjectManagerPort\"),\n",
    "                \"raylet_socket_name\": n.get(\"raylet_socket_name\"),\n",
    "            },\n",
    "            \"additional\": {},\n",
    "        }\n",
    "\n",
    "        # Keep extra keys but avoid huge dumps\n",
    "        keep_extra = [\n",
    "            \"StartTime\", \"StartTimeMs\", \"StartTimeNS\",\n",
    "            \"State\", \"DeathCause\", \"IsHead\", \"NodeManagerAddress\",\n",
    "        ]\n",
    "        for k in keep_extra:\n",
    "            if k in n:\n",
    "                out[\"additional\"][k] = n.get(k)\n",
    "\n",
    "        # Some Ray builds include \"Resources\" and also \"ResourcesTotal\" or similar\n",
    "        for k in [\"ResourcesTotal\", \"ResourcesTotalMap\", \"ResourcesAvailable\", \"ResourcesAvailableMap\"]:\n",
    "            if k in n:\n",
    "                out[\"additional\"][k] = n.get(k)\n",
    "\n",
    "        return out\n",
    "\n",
    "    node_summaries = [_node_summary(n) for n in node_list]\n",
    "\n",
    "    result[\"nodes\"] = {\n",
    "        \"total_detected\": len(node_list),\n",
    "        \"alive\": len(alive),\n",
    "        \"dead\": len(dead),\n",
    "        \"summaries\": node_summaries,\n",
    "    }\n",
    "\n",
    "    if len(node_list) == 0:\n",
    "        result[\"warnings\"].append(\"No nodes returned by ray.nodes(); cluster may be unreachable or in a bad state.\")\n",
    "\n",
    "    # --- Autoscaler status (best effort, varies by Ray + deployment) ---\n",
    "    autoscaler_info: Dict[str, Any] = {}\n",
    "    if include_internal_kv:\n",
    "        # Newer Ray: ray._private.internal_kv; key names vary.\n",
    "        try:\n",
    "            from ray._private import internal_kv  # type: ignore\n",
    "            # internal KV needs init; should already be via ray.init\n",
    "            internal_kv._internal_kv_initialized()  # may not exist in all versions\n",
    "        except Exception:\n",
    "            internal_kv = None  # type: ignore\n",
    "\n",
    "        if internal_kv is not None:\n",
    "            # Try common autoscaler keys\n",
    "            keys_to_try = [\n",
    "                b\"autoscaler/status\",                 # sometimes used\n",
    "                b\"autoscaler/summary\",                # sometimes used\n",
    "                b\"ray_autoscaler/status\",             # sometimes used\n",
    "                b\"RAY_AUTOSCALER_STATUS\",             # sometimes used\n",
    "            ]\n",
    "            found_any = False\n",
    "            for k in keys_to_try:\n",
    "                v, e = _safe(internal_kv._internal_kv_get, k)  # type: ignore\n",
    "                if v:\n",
    "                    found_any = True\n",
    "                    try:\n",
    "                        autoscaler_info[k.decode(\"utf-8\", \"ignore\")] = v.decode(\"utf-8\", \"ignore\")\n",
    "                    except Exception:\n",
    "                        autoscaler_info[k.decode(\"utf-8\", \"ignore\")] = str(v)\n",
    "            if not found_any:\n",
    "                autoscaler_info[\"note\"] = \"No known autoscaler keys found in internal KV (this can be normal).\"\n",
    "        else:\n",
    "            autoscaler_info[\"note\"] = \"ray._private.internal_kv unavailable; skipping internal KV autoscaler lookup.\"\n",
    "    result[\"cluster\"][\"autoscaler\"] = autoscaler_info\n",
    "\n",
    "    # --- Placement groups / Actors / Tasks (best effort: Ray APIs differ by version) ---\n",
    "    # Placement groups\n",
    "    if include_placement_groups:\n",
    "        pg_out: Dict[str, Any] = {\"available\": False, \"items\": []}\n",
    "        try:\n",
    "            from ray.util.placement_group import list_placement_groups  # type: ignore\n",
    "            pgs, e = _safe(list_placement_groups)\n",
    "            if pgs is not None:\n",
    "                pg_out[\"available\"] = True\n",
    "                # pgs can be list[PlacementGroup] or dict-like\n",
    "                items = []\n",
    "                for pg in pgs:\n",
    "                    try:\n",
    "                        # Try to access fields safely\n",
    "                        items.append({\n",
    "                            \"id\": str(getattr(pg, \"id\", None) or getattr(pg, \"placement_group_id\", None)),\n",
    "                            \"name\": getattr(pg, \"name\", None),\n",
    "                            \"state\": str(getattr(pg, \"state\", None)),\n",
    "                            \"bundles\": getattr(pg, \"bundles\", None),\n",
    "                            \"strategy\": getattr(pg, \"strategy\", None),\n",
    "                        })\n",
    "                    except Exception:\n",
    "                        items.append({\"raw\": str(pg)})\n",
    "                pg_out[\"items\"] = items\n",
    "            if e:\n",
    "                pg_out[\"error\"] = e\n",
    "        except Exception as e:\n",
    "            pg_out[\"error\"] = str(e)\n",
    "        result[\"cluster\"][\"placement_groups\"] = pg_out\n",
    "\n",
    "    # Actors / tasks: prefer state API if present\n",
    "    state_out: Dict[str, Any] = {\"available\": False}\n",
    "    if include_actors or include_tasks:\n",
    "        try:\n",
    "            from ray.util.state import list_actors, list_tasks  # type: ignore\n",
    "            state_out[\"available\"] = True\n",
    "            if include_actors:\n",
    "                actors, e = _safe(list_actors, limit=1000)\n",
    "                state_out[\"actors\"] = {\n",
    "                    \"count\": len(actors) if actors else 0,\n",
    "                    \"sample\": (actors[:25] if actors else []),\n",
    "                    \"error\": e,\n",
    "                }\n",
    "            if include_tasks:\n",
    "                tasks, e = _safe(list_tasks, limit=1000)\n",
    "                state_out[\"tasks\"] = {\n",
    "                    \"count\": len(tasks) if tasks else 0,\n",
    "                    \"sample\": (tasks[:25] if tasks else []),\n",
    "                    \"error\": e,\n",
    "                }\n",
    "        except Exception as e:\n",
    "            state_out[\"error\"] = str(e)\n",
    "    result[\"cluster\"][\"state_api\"] = state_out\n",
    "\n",
    "    # --- Probes ---\n",
    "    probes: Dict[str, Any] = {}\n",
    "\n",
    "    # A remote function to report execution context and node-level details.\n",
    "    @ray.remote\n",
    "    def _node_probe() -> Dict[str, Any]:\n",
    "        import os, socket, time, platform\n",
    "        import ray\n",
    "        ctx = ray.get_runtime_context()\n",
    "        # CPU count here is logical cores visible to the worker proc.\n",
    "        try:\n",
    "            import psutil  # optional, might not exist in your image\n",
    "            mem = psutil.virtual_memory()._asdict()\n",
    "            cpu_count = psutil.cpu_count(logical=True)\n",
    "        except Exception:\n",
    "            mem = None\n",
    "            cpu_count = os.cpu_count()\n",
    "\n",
    "        return {\n",
    "            \"ts\": time.time(),\n",
    "            \"hostname\": socket.gethostname(),\n",
    "            \"ip\": ray.util.get_node_ip_address(),\n",
    "            \"pid\": os.getpid(),\n",
    "            \"python\": platform.python_version(),\n",
    "            \"platform\": platform.platform(),\n",
    "            \"ray_node_id\": str(ctx.get_node_id()),\n",
    "            \"worker_id\": str(getattr(ctx, \"get_worker_id\", lambda: None)() or \"\"),\n",
    "            \"job_id\": str(ctx.get_job_id()),\n",
    "            \"namespace\": str(ctx.namespace),\n",
    "            \"cpu_count\": cpu_count,\n",
    "            \"mem\": mem,\n",
    "            \"env_sample\": {\n",
    "                \"RAY_ADDRESS\": os.environ.get(\"RAY_ADDRESS\"),\n",
    "                \"OMP_NUM_THREADS\": os.environ.get(\"OMP_NUM_THREADS\"),\n",
    "            },\n",
    "        }\n",
    "\n",
    "    # Determine unique node IDs & schedule one probe per node\n",
    "    # We do this by using custom resources that Ray sets: \"node:<node_id>\" typically exists.\n",
    "    # If absent, we fall back to scheduling N probes and deduplicating by node_id.\n",
    "    node_resource_keys = []\n",
    "    if isinstance(cr, dict):\n",
    "        node_resource_keys = [k for k in cr.keys() if isinstance(k, str) and k.startswith(\"node:\")]\n",
    "\n",
    "    per_node_exec: Dict[str, Any] = {\"attempted\": False, \"results\": [], \"errors\": []}\n",
    "    if run_per_node_exec_probe:\n",
    "        per_node_exec[\"attempted\"] = True\n",
    "        try:\n",
    "            futures = []\n",
    "            if node_resource_keys:\n",
    "                for nk in node_resource_keys:\n",
    "                    # Force placement on that node by requiring its unique node resource.\n",
    "                    futures.append(_node_probe.options(resources={nk: 0.001}).remote())\n",
    "            else:\n",
    "                # Fallback: schedule as many probes as alive nodes (or 1) and dedupe\n",
    "                n = max(1, len(alive))\n",
    "                futures = [_node_probe.remote() for _ in range(n)]\n",
    "\n",
    "            # Gather with timeout\n",
    "            start = time.time()\n",
    "            out = []\n",
    "            remaining = list(futures)\n",
    "            while remaining and (time.time() - start) < per_node_timeout_s:\n",
    "                done, pending = ray.wait(remaining, num_returns=1, timeout=0.5)\n",
    "                if done:\n",
    "                    out.extend(ray.get(done))\n",
    "                remaining = pending\n",
    "\n",
    "            if remaining:\n",
    "                per_node_exec[\"errors\"].append(f\"Timeout waiting for {len(remaining)} node probe tasks.\")\n",
    "                # Attempt to fetch any that did finish later without blocking too long\n",
    "                try:\n",
    "                    done_now, _ = ray.wait(remaining, num_returns=len(remaining), timeout=0.1)\n",
    "                    if done_now:\n",
    "                        out.extend(ray.get(done_now))\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "            # Deduplicate by ray_node_id\n",
    "            by_node: Dict[str, Dict[str, Any]] = {}\n",
    "            for r in out:\n",
    "                by_node[r.get(\"ray_node_id\", f\"unknown-{len(by_node)}\")] = r\n",
    "\n",
    "            per_node_exec[\"results\"] = list(by_node.values())\n",
    "            per_node_exec[\"summary\"] = {\n",
    "                \"unique_nodes_returned\": len(by_node),\n",
    "                \"requested\": len(futures),\n",
    "            }\n",
    "        except Exception as e:\n",
    "            per_node_exec[\"errors\"].append(str(e))\n",
    "            per_node_exec[\"errors\"].append(traceback.format_exc())\n",
    "\n",
    "    probes[\"per_node_exec_probe\"] = per_node_exec\n",
    "\n",
    "    # Object store probe (put/get a few MB)\n",
    "    if run_object_store_probe:\n",
    "        obj_probe: Dict[str, Any] = {\"attempted\": True}\n",
    "        try:\n",
    "            import numpy as np  # usually available\n",
    "            size_mb = 8\n",
    "            arr = np.random.randint(0, 255, size=(size_mb * 1024 * 1024,), dtype=np.uint8)\n",
    "\n",
    "            t0 = time.time()\n",
    "            ref = ray.put(arr)\n",
    "            t1 = time.time()\n",
    "            got = ray.get(ref)\n",
    "            t2 = time.time()\n",
    "\n",
    "            obj_probe.update({\n",
    "                \"size_mb\": size_mb,\n",
    "                \"put_seconds\": t1 - t0,\n",
    "                \"get_seconds\": t2 - t1,\n",
    "                \"roundtrip_seconds\": t2 - t0,\n",
    "                \"checksum\": int(got[:1024].sum()),  # tiny sanity check\n",
    "            })\n",
    "        except Exception as e:\n",
    "            obj_probe[\"error\"] = str(e)\n",
    "            obj_probe[\"traceback\"] = traceback.format_exc()\n",
    "        probes[\"object_store_probe\"] = obj_probe\n",
    "\n",
    "    # Optional CPU burn (distributed) to validate scheduling + concurrency\n",
    "    if run_cpu_burn_probe:\n",
    "        burn: Dict[str, Any] = {\"attempted\": True, \"seconds_each\": cpu_burn_seconds}\n",
    "        try:\n",
    "            @ray.remote\n",
    "            def _burn(seconds: float) -> Dict[str, Any]:\n",
    "                import time, math, socket\n",
    "                import ray\n",
    "                end = time.time() + seconds\n",
    "                x = 0.0\n",
    "                i = 0\n",
    "                while time.time() < end:\n",
    "                    x += math.sin(i) * math.cos(i)\n",
    "                    i += 1\n",
    "                return {\n",
    "                    \"hostname\": socket.gethostname(),\n",
    "                    \"ip\": ray.util.get_node_ip_address(),\n",
    "                    \"iters\": i,\n",
    "                    \"acc\": x,\n",
    "                }\n",
    "\n",
    "            # Try one burn per alive node, else 1\n",
    "            n = max(1, len(alive))\n",
    "            t0 = time.time()\n",
    "            outs = ray.get([_burn.remote(cpu_burn_seconds) for _ in range(n)])\n",
    "            t1 = time.time()\n",
    "\n",
    "            burn[\"tasks\"] = n\n",
    "            burn[\"wall_seconds\"] = t1 - t0\n",
    "            burn[\"results_sample\"] = outs[: min(25, len(outs))]\n",
    "        except Exception as e:\n",
    "            burn[\"error\"] = str(e)\n",
    "            burn[\"traceback\"] = traceback.format_exc()\n",
    "        probes[\"cpu_burn_probe\"] = burn\n",
    "\n",
    "    result[\"probes\"] = probes\n",
    "\n",
    "    # High-level sanity warnings\n",
    "    if result[\"nodes\"][\"alive\"] == 0:\n",
    "        result[\"warnings\"].append(\"Ray reports 0 alive nodes.\")\n",
    "    if isinstance(cr, dict) and \"CPU\" in cr and cr.get(\"CPU\", 0) == 0:\n",
    "        result[\"warnings\"].append(\"Cluster resources show CPU=0; scheduler may be unhealthy or nodes not registered.\")\n",
    "    if run_per_node_exec_probe and per_node_exec.get(\"summary\"):\n",
    "        uniq = per_node_exec[\"summary\"].get(\"unique_nodes_returned\", 0)\n",
    "        if uniq < max(1, len(alive)):\n",
    "            result[\"warnings\"].append(\n",
    "                f\"Per-node exec probe returned {uniq} unique nodes, but ray.nodes() shows {len(alive)} alive nodes.\"\n",
    "            )\n",
    "\n",
    "    if verbose:\n",
    "        # Pretty print a compact summary to stdout\n",
    "        print(\"=== Ray Cluster Test Summary ===\")\n",
    "        print(\"Ray:\", result[\"meta\"].get(\"ray_version\"))\n",
    "        print(\"Address:\", result[\"connection\"].get(\"address_requested\"))\n",
    "        print(\"Dashboard:\", result[\"connection\"].get(\"dashboard_url\"))\n",
    "        print(\"Nodes detected:\", result[\"nodes\"][\"total_detected\"],\n",
    "              \"| alive:\", result[\"nodes\"][\"alive\"],\n",
    "              \"| dead:\", result[\"nodes\"][\"dead\"])\n",
    "        print(\"Cluster resources:\", result[\"cluster\"].get(\"cluster_resources\", {}))\n",
    "        print(\"Available resources:\", result[\"cluster\"].get(\"available_resources\", {}))\n",
    "        if run_per_node_exec_probe:\n",
    "            s = result[\"probes\"][\"per_node_exec_probe\"].get(\"summary\", {})\n",
    "            print(\"Per-node probe:\", s)\n",
    "        if run_object_store_probe:\n",
    "            op = result[\"probes\"].get(\"object_store_probe\", {})\n",
    "            if \"error\" in op:\n",
    "                print(\"Object store probe: ERROR\")\n",
    "            else:\n",
    "                print(\"Object store probe (MB):\", op.get(\"size_mb\"),\n",
    "                      \"| put:\", round(op.get(\"put_seconds\", 0), 4),\n",
    "                      \"| get:\", round(op.get(\"get_seconds\", 0), 4),\n",
    "                      \"| rt:\", round(op.get(\"roundtrip_seconds\", 0), 4))\n",
    "        if result[\"warnings\"]:\n",
    "            print(\"Warnings:\", len(result[\"warnings\"]))\n",
    "            for w in result[\"warnings\"][:10]:\n",
    "                print(\"-\", w)\n",
    "        if result[\"errors\"]:\n",
    "            print(\"Errors:\", len(result[\"errors\"]))\n",
    "            for e in result[\"errors\"][:3]:\n",
    "                print(\"-\", e)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32d93d5f-f74f-4ebe-8011-ffc293d22c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-13 15:55:09,105\tINFO worker.py:1821 -- Connecting to existing Ray cluster at address: 172.31.22.212:6379...\n",
      "2026-01-13 15:55:09,106\tINFO worker.py:1839 -- Calling ray.init() again after it has already been called.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Ray Cluster Test Summary ===\n",
      "Ray: 2.53.0\n",
      "Address: auto\n",
      "Dashboard: 127.0.0.1:8265\n",
      "Nodes detected: 3 | alive: 3 | dead: 0\n",
      "Cluster resources: {'node:172.31.24.15': 1.0, 'CPU': 10.0, 'memory': 16230511002.0, 'object_store_memory': 6955933286.0, 'node:__internal_head__': 1.0, 'node:172.31.22.212': 1.0, 'node:172.31.31.22': 1.0}\n",
      "Available resources: {'node:172.31.24.15': 1.0, 'CPU': 10.0, 'object_store_memory': 6955933286.0, 'memory': 16230511002.0, 'node:__internal_head__': 1.0, 'node:172.31.22.212': 1.0, 'node:172.31.31.22': 1.0}\n",
      "Per-node probe: {'unique_nodes_returned': 3, 'requested': 4}\n",
      "Object store probe (MB): 8 | put: 0.002 | get: 0.0006 | rt: 0.0026\n",
      "{\n",
      "  \"meta\": {\n",
      "    \"timestamp_utc\": \"2026-01-13T15:55:09Z\",\n",
      "    \"host\": \"ip-172-31-22-212.eu-west-2.compute.internal\",\n",
      "    \"platform\": \"Linux-6.1.159-181.297.amzn2023.x86_64-x86_64-with-glibc2.41\",\n",
      "    \"python\": \"3.11.14\",\n",
      "    \"pid\": 762,\n",
      "    \"env\": {\n",
      "      \"RAY_ADDRESS\": null,\n",
      "      \"RAY_NAMESPACE\": null\n",
      "    },\n",
      "    \"ray_version\": \"2.53.0\"\n",
      "  },\n",
      "  \"connection\": {\n",
      "    \"address_requested\": \"auto\",\n",
      "    \"dashboard_url\": \"127.0.0.1:8265\",\n",
      "    \"redis_address\": null,\n",
      "    \"raylet_socket_name\": \"/tmp/ray/session_2026-01-13_15-46-38_156629_9/sockets/raylet\"\n",
      "  },\n",
      "  \"cluster\": {\n",
      "    \"cluster_resources\": {\n",
      "      \"node:172.31.24.15\": 1.0,\n",
      "      \"CPU\": 10.0,\n",
      "      \"memory\": 16230511002.0,\n",
      "      \"object_store_memory\": 6955933286.0,\n",
      "      \"node:__internal_head__\": 1.0,\n",
      "      \"node:172.31.22.212\": 1.0,\n",
      "      \"node:172.31.31.22\": 1.0\n",
      "    },\n",
      "    \"available_resources\": {\n",
      "      \"node:172.31.24.15\": 1.0,\n",
      "      \"CPU\": 10.0,\n",
      "      \"object_store_memory\": 6955933286.0,\n",
      "      \"memory\": 16230511002.0,\n",
      "      \"node:__internal_head__\": 1.0,\n",
      "      \"node:172.31.22.212\": 1.0,\n",
      "      \"node:172.31.31.22\": 1.0\n",
      "    },\n",
      "    \"autoscaler\": {\n",
      "      \"note\": \"ray._private.internal_kv unavailable; skipping internal KV autoscaler lookup.\"\n",
      "    },\n",
      "    \"placement_groups\": {\n",
      "      \"available\": false,\n",
      "      \"items\": [],\n",
      "      \"error\": \"cannot import name 'list_placement_groups' from 'ray.util.placement_group' (/usr/local/lib/python3.11/site-packages/ray/util/placement_group.py)\"\n",
      "    },\n",
      "    \"state_api\": {\n",
      "      \"available\": true,\n",
      "      \"actors\": {\n",
      "        \"count\": 0,\n",
      "        \"sample\": [],\n",
      "        \"error\": null\n",
      "      },\n",
      "      \"tasks\": {\n",
      "        \"count\": 4,\n",
      "        \"sample\": [\n",
      "          \"TaskState(task_id='39088be3736e590affffffffffffffffffffffff02000000', attempt_number=0, name='_node_probe', state='FINISHED', job_id='02000000', actor_id=None, type='NORMAL_TASK', func_or_class_name='_node_probe', parent_task_id='ffffffffffffffffffffffffffffffffffffffff02000000', node_id='11a3ce08bfb6be829191f7758a4f8e5faa3f46bb8303dbde37436c93', worker_id='6216dff482ed2a17f6c773cddb4d09f5eee9c93fb254071a5d19a4d4', worker_pid=180, error_type=None, language=None, required_resources=None, runtime_env_info=None, placement_group_id=None, events=None, profiling_data=None, creation_time_ms=None, start_time_ms=None, end_time_ms=None, task_log_info=None, error_message=None, is_debugger_paused=None, call_site=None, label_selector=None)\",\n",
      "          \"TaskState(task_id='67a2e8cfa5a06db3ffffffffffffffffffffffff02000000', attempt_number=0, name='_node_probe', state='FINISHED', job_id='02000000', actor_id=None, type='NORMAL_TASK', func_or_class_name='_node_probe', parent_task_id='ffffffffffffffffffffffffffffffffffffffff02000000', node_id='de5c7513e8d97c2efd17194571f2a8f37a3f9f524eb898cb13648b56', worker_id='e80d452191419e55d632c720fb1f58d05e30e96263dd92914231d93f', worker_pid=179, error_type=None, language=None, required_resources=None, runtime_env_info=None, placement_group_id=None, events=None, profiling_data=None, creation_time_ms=None, start_time_ms=None, end_time_ms=None, task_log_info=None, error_message=None, is_debugger_paused=None, call_site=None, label_selector=None)\",\n",
      "          \"TaskState(task_id='e082c90ab8422b00ffffffffffffffffffffffff02000000', attempt_number=0, name='_node_probe', state='FINISHED', job_id='02000000', actor_id=None, type='NORMAL_TASK', func_or_class_name='_node_probe', parent_task_id='ffffffffffffffffffffffffffffffffffffffff02000000', node_id='dbd076482fb7bc264ffcccc37d38ddae9fc1562fb79c6980a06e5de9', worker_id='c15cbbb1b329f14d2390a59bcd99b9333cd9355060d3d1fba33598e5', worker_pid=402, error_type=None, language=None, required_resources=None, runtime_env_info=None, placement_group_id=None, events=None, profiling_data=None, creation_time_ms=None, start_time_ms=None, end_time_ms=None, task_log_info=None, error_message=None, is_debugger_paused=None, call_site=None, label_selector=None)\",\n",
      "          \"TaskState(task_id='e5cbd90b7f1fb776ffffffffffffffffffffffff02000000', attempt_number=0, name='_node_probe', state='FINISHED', job_id='02000000', actor_id=None, type='NORMAL_TASK', func_or_class_name='_node_probe', parent_task_id='ffffffffffffffffffffffffffffffffffffffff02000000', node_id='dbd076482fb7bc264ffcccc37d38ddae9fc1562fb79c6980a06e5de9', worker_id='bfc90a12bdc6fac1c06e501700897e13dddb4173b85d73452584ba20', worker_pid=403, error_type=None, language=None, required_resources=None, runtime_env_info=None, placement_group_id=None, events=None, profiling_data=None, creation_time_ms=None, start_time_ms=None, end_time_ms=None, task_log_info=None, error_message=None, is_debugger_paused=None, call_site=None, label_selector=None)\"\n",
      "        ],\n",
      "        \"error\": null\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"nodes\": {\n",
      "    \"total_detected\": 3,\n",
      "    \"alive\": 3,\n",
      "    \"dead\": 0,\n",
      "    \"summaries\": [\n",
      "      {\n",
      "        \"node_id\": \"dbd076482fb7bc264ffcccc37d38ddae9fc1562fb79c6980a06e5de9\",\n",
      "        \"alive\": true,\n",
      "        \"node_name\": \"172.31.22.212\",\n",
      "        \"ip\": \"172.31.22.212\",\n",
      "        \"resources_total\": {\n",
      "          \"node:__internal_head__\": 1.0,\n",
      "          \"CPU\": 2.0,\n",
      "          \"node:172.31.22.212\": 1.0,\n",
      "          \"memory\": 4926792909.0,\n",
      "          \"object_store_memory\": 2111482675.0\n",
      "        },\n",
      "        \"labels\": {\n",
      "          \"ray.io/node-id\": \"dbd076482fb7bc264ffcccc37d38ddae9fc1562fb79c6980a06e5de9\"\n",
      "        },\n",
      "        \"raylet\": {\n",
      "          \"node_manager_hostname\": \"ip-172-31-22-212.eu-west-2.compute.internal\",\n",
      "          \"node_manager_port\": 40069,\n",
      "          \"object_manager_port\": 34285,\n",
      "          \"raylet_socket_name\": null\n",
      "        },\n",
      "        \"additional\": {\n",
      "          \"NodeManagerAddress\": \"172.31.22.212\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"node_id\": \"11a3ce08bfb6be829191f7758a4f8e5faa3f46bb8303dbde37436c93\",\n",
      "        \"alive\": true,\n",
      "        \"node_name\": \"172.31.31.22\",\n",
      "        \"ip\": \"172.31.31.22\",\n",
      "        \"resources_total\": {\n",
      "          \"node:172.31.31.22\": 1.0,\n",
      "          \"CPU\": 4.0,\n",
      "          \"memory\": 5651821773.0,\n",
      "          \"object_store_memory\": 2422209331.0\n",
      "        },\n",
      "        \"labels\": {\n",
      "          \"ray.io/node-id\": \"11a3ce08bfb6be829191f7758a4f8e5faa3f46bb8303dbde37436c93\"\n",
      "        },\n",
      "        \"raylet\": {\n",
      "          \"node_manager_hostname\": \"ip-172-31-31-22.eu-west-2.compute.internal\",\n",
      "          \"node_manager_port\": 43877,\n",
      "          \"object_manager_port\": 39751,\n",
      "          \"raylet_socket_name\": null\n",
      "        },\n",
      "        \"additional\": {\n",
      "          \"NodeManagerAddress\": \"172.31.31.22\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"node_id\": \"de5c7513e8d97c2efd17194571f2a8f37a3f9f524eb898cb13648b56\",\n",
      "        \"alive\": true,\n",
      "        \"node_name\": \"172.31.24.15\",\n",
      "        \"ip\": \"172.31.24.15\",\n",
      "        \"resources_total\": {\n",
      "          \"node:172.31.24.15\": 1.0,\n",
      "          \"CPU\": 4.0,\n",
      "          \"memory\": 5651896320.0,\n",
      "          \"object_store_memory\": 2422241280.0\n",
      "        },\n",
      "        \"labels\": {\n",
      "          \"ray.io/node-id\": \"de5c7513e8d97c2efd17194571f2a8f37a3f9f524eb898cb13648b56\"\n",
      "        },\n",
      "        \"raylet\": {\n",
      "          \"node_manager_hostname\": \"ip-172-31-24-15.eu-west-2.compute.internal\",\n",
      "          \"node_manager_port\": 39939,\n",
      "          \"object_manager_port\": 44249,\n",
      "          \"raylet_socket_name\": null\n",
      "        },\n",
      "        \"additional\": {\n",
      "          \"NodeManagerAddress\": \"172.31.24.15\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"probes\": {\n",
      "    \"per_node_exec_probe\": {\n",
      "      \"attempted\": true,\n",
      "      \"results\": [\n",
      "        {\n",
      "          \"ts\": 1768319709.1309357,\n",
      "          \"hostname\": \"ip-172-31-22-212.eu-west-2.compute.internal\",\n",
      "          \"ip\": \"172.31.22.212\",\n",
      "          \"pid\": 403,\n",
      "          \"python\": \"3.11.14\",\n",
      "          \"platform\": \"Linux-6.1.159-181.297.amzn2023.x86_64-x86_64-with-glibc2.41\",\n",
      "          \"ray_node_id\": \"dbd076482fb7bc264ffcccc37d38ddae9fc1562fb79c6980a06e5de9\",\n",
      "          \"worker_id\": \"bfc90a12bdc6fac1c06e501700897e13dddb4173b85d73452584ba20\",\n",
      "          \"job_id\": \"02000000\",\n",
      "          \"namespace\": \"ray_cluster_test\",\n",
      "          \"cpu_count\": 2,\n",
      "          \"mem\": {\n",
      "            \"total\": 8161673216,\n",
      "            \"available\": 5506654208,\n",
      "            \"percent\": 32.5,\n",
      "            \"used\": 2655019008,\n",
      "            \"free\": 124887040,\n",
      "            \"active\": 344567808,\n",
      "            \"inactive\": 6836899840,\n",
      "            \"buffers\": 1638400,\n",
      "            \"cached\": 5701132288,\n",
      "            \"shared\": 8945664,\n",
      "            \"slab\": 581828608\n",
      "          },\n",
      "          \"env_sample\": {\n",
      "            \"RAY_ADDRESS\": null,\n",
      "            \"OMP_NUM_THREADS\": \"1\"\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"ts\": 1768319709.1317346,\n",
      "          \"hostname\": \"ip-172-31-24-15.eu-west-2.compute.internal\",\n",
      "          \"ip\": \"172.31.24.15\",\n",
      "          \"pid\": 179,\n",
      "          \"python\": \"3.11.14\",\n",
      "          \"platform\": \"Linux-6.1.159-181.297.amzn2023.x86_64-x86_64-with-glibc2.41\",\n",
      "          \"ray_node_id\": \"de5c7513e8d97c2efd17194571f2a8f37a3f9f524eb898cb13648b56\",\n",
      "          \"worker_id\": \"e80d452191419e55d632c720fb1f58d05e30e96263dd92914231d93f\",\n",
      "          \"job_id\": \"02000000\",\n",
      "          \"namespace\": \"ray_cluster_test\",\n",
      "          \"cpu_count\": 4,\n",
      "          \"mem\": {\n",
      "            \"total\": 8161181696,\n",
      "            \"available\": 6895681536,\n",
      "            \"percent\": 15.5,\n",
      "            \"used\": 1265500160,\n",
      "            \"free\": 1074380800,\n",
      "            \"active\": 311394304,\n",
      "            \"inactive\": 5970493440,\n",
      "            \"buffers\": 3248128,\n",
      "            \"cached\": 6130679808,\n",
      "            \"shared\": 569344,\n",
      "            \"slab\": 557129728\n",
      "          },\n",
      "          \"env_sample\": {\n",
      "            \"RAY_ADDRESS\": null,\n",
      "            \"OMP_NUM_THREADS\": \"1\"\n",
      "          }\n",
      "        },\n",
      "        {\n",
      "          \"ts\": 1768319709.13185,\n",
      "          \"hostname\": \"ip-172-31-31-22.eu-west-2.compute.internal\",\n",
      "          \"ip\": \"172.31.31.22\",\n",
      "          \"pid\": 180,\n",
      "          \"python\": \"3.11.14\",\n",
      "          \"platform\": \"Linux-6.1.159-181.297.amzn2023.x86_64-x86_64-with-glibc2.41\",\n",
      "          \"ray_node_id\": \"11a3ce08bfb6be829191f7758a4f8e5faa3f46bb8303dbde37436c93\",\n",
      "          \"worker_id\": \"6216dff482ed2a17f6c773cddb4d09f5eee9c93fb254071a5d19a4d4\",\n",
      "          \"job_id\": \"02000000\",\n",
      "          \"namespace\": \"ray_cluster_test\",\n",
      "          \"cpu_count\": 4,\n",
      "          \"mem\": {\n",
      "            \"total\": 8161181696,\n",
      "            \"available\": 6889455616,\n",
      "            \"percent\": 15.6,\n",
      "            \"used\": 1271726080,\n",
      "            \"free\": 1068040192,\n",
      "            \"active\": 311414784,\n",
      "            \"inactive\": 5971726336,\n",
      "            \"buffers\": 3248128,\n",
      "            \"cached\": 6130790400,\n",
      "            \"shared\": 565248,\n",
      "            \"slab\": 564031488\n",
      "          },\n",
      "          \"env_sample\": {\n",
      "            \"RAY_ADDRESS\": null,\n",
      "            \"OMP_NUM_THREADS\": \"1\"\n",
      "          }\n",
      "        }\n",
      "      ],\n",
      "      \"errors\": [],\n",
      "      \"summary\": {\n",
      "        \"unique_nodes_returned\": 3,\n",
      "        \"requested\": 4\n",
      "      }\n",
      "    },\n",
      "    \"object_store_probe\": {\n",
      "      \"attempted\": true,\n",
      "      \"size_mb\": 8,\n",
      "      \"put_seconds\": 0.0019974708557128906,\n",
      "      \"get_seconds\": 0.0005536079406738281,\n",
      "      \"roundtrip_seconds\": 0.0025510787963867188,\n",
      "      \"checksum\": 132071\n",
      "    }\n",
      "  },\n",
      "  \"warnings\": [],\n",
      "  \"errors\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "out = test_ray_cluster(\n",
    "    address=\"auto\",\n",
    "    run_cpu_burn_probe=False,   # flip to True if you want a distributed compute sanity test\n",
    "    cpu_burn_seconds=1.0,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# If you want a JSON blob to save:\n",
    "import json\n",
    "print(json.dumps(out, indent=2, default=str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8db0439-2abe-437c-a0ae-c3457a227a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
